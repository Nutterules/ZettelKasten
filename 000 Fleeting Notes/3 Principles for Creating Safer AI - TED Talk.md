https://www.youtube.com/watch?v=EBK-a94IFHY&ab_channel=TED


- problem with creating super intelligent AI - could lead to our extinction 
- ALan turing: even if we could turn machine off then we should still be humbled as a species 
	- off switch problem:
		- machine that makes coffee
		- realises it can't make coffee if it's dead 
		- disabled off switch (and taser starbucks customers who might interfere with it)
		- This is the problem with having a concrete defined objective 
	
- we need to be sure that what we tell the machines to do is actually what we want (norbert wiener, 1960)
	- single minded persuit by the machine of a goal 
	- king midas: everything i touch turn to gold ==> family and food all gold and he dies miserable and alone


therefore we should seek to create AI that: 
	- it's only objective is maximising the realisation of human goals 
		- ie it's not self interested so it won't stop itself being turned off
	- it doesn't know those goals initially 
		- removes the single minded pursuit
	- is informed by human behaviour by what we want 
		- my problem with this though is that often we don't act in accordance with what we value so it will learn the wrong things 


Of switch problem but with uncertain principles:
- might be switched off 
- but only if doing something wrong 
- no knowledge of what is 'wrong'
- therefore let human switch me off 
- can caluclate incentive robot has to be switched off and it's directly tied to degree of uncertainty about undelying objective. 
- if it is switched off then it learns it wasn't doing the right thing 

he mentions human bad behaviour: 
- it won't necessarily copy your behaviour, it will understand motivations and maybe help you resist temptation 
- main difficult is getting a machine to predict what life **any** person might prefer


further difficulties in stopping it doing bad things to achieve fgo